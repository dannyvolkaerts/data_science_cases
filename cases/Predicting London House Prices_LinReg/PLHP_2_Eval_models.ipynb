{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importeer de benodigde bibliotheken, dan gaat het later sneller \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from catboost import CatBoostRegressor\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "# interactieve modus inschakelen en output verbreden\n",
    "%matplotlib inline\n",
    "pd.set_option('display.width', 800)\n",
    "\n",
    "# remove future warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      ".\\london-house-price-prediction-advanced-techniques.zip\n",
      ".\\PLHP_1_CatBoostRegressor.ipynb\n",
      ".\\PLHP_2_Eval_models copy.ipynb\n",
      ".\\PLHP_2_Eval_models.ipynb\n",
      ".\\PLHP_3_Pipelines.ipynb\n",
      ".\\test_kaggle_DL.ipynb\n",
      ".\\catboost_info\\catboost_training.json\n",
      ".\\catboost_info\\learn\\events.out.tfevents\n",
      ".\\catboost_info\\test\\events.out.tfevents\n",
      ".\\data\\sample_submission.csv\n",
      ".\\data\\test.csv\n",
      ".\\data\\train.csv\n",
      ".\\images\\model_comparison.png\n",
      ".\\output\\profiler.html\n",
      ".\\output\\profiler_raw.html\n",
      ".\\output\\submission.csv\n",
      ".\\output\\submission_cbr_log.csv\n"
     ]
    }
   ],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "# path settings\n",
    "from pathlib import Path\n",
    "p = Path()\n",
    "download_path = p / 'data'\n",
    "output_path = p / 'output'\n",
    "\n",
    "# download the data is niet gelukt, dus maar manueel gedaan\n",
    "\n",
    "# Lees het bestand in\n",
    "print(p)\n",
    "for dirname, _, filenames in os.walk(p):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        if 'train' in filename:\n",
    "            train_set = os.path.join(dirname, filename)\n",
    "            break\n",
    "\n",
    "train_raw = pd.read_csv(train_set, index_col='ID')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "data = train_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functie om de output van de gemaakte plots te bewaren\n",
    "\n",
    "images_path = p / 'images'\n",
    "\n",
    "# Create the images directory if it does not exist\n",
    "if not images_path.exists():\n",
    "\timages_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_name, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = images_path / f\"{fig_name}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functie om NaN-waarden te behandelen\n",
    "\n",
    "# Lijst om kolommen met >50% missende waarden op te slaan\n",
    "cols_to_drop = []\n",
    "\n",
    "def fill_missing_values(df):\n",
    "    for col, missing_count in df.isnull().sum().items():\n",
    "        missing_ratio = missing_count / len(df)\n",
    "        \n",
    "        if 0 < missing_ratio <= 0.5:\n",
    "            if df[col].dtype == object:  # Categorische kolommen\n",
    "                df[col] = df[col].fillna(df[col].mode()[0])\n",
    "            else:  # Numerieke kolommen\n",
    "                df[col] = df[col].fillna(df[col].median())\n",
    "        \n",
    "        elif missing_ratio > 0.5:\n",
    "            cols_to_drop.append(col)\n",
    "\n",
    "# Kolommen met te veel missende waarden verwijderen\n",
    "data = data.drop(columns=cols_to_drop)\n",
    "\n",
    "del cols_to_drop  # Opschoonactie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Er zijn geen missende waarden\n"
     ]
    }
   ],
   "source": [
    "# Missende waarden invullen in test- en train-data en kilommen met te veel lege waarden droppen\n",
    "# alleen uitvoeren indien nog lege waarden\n",
    "if data.isnull().sum().sum() > 0:\n",
    "    fill_missing_values(test)\n",
    "    fill_missing_values(data)\n",
    "    print(f\"De lege waarden werdenn opgevuld en de kolommen met te veel missende waarden zijn verwijderd\")\n",
    "else:\n",
    "    print(\"Er zijn geen missende waarden\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fullAddress: 118345 unieke waarden\n",
      "postcode: 45064 unieke waarden\n",
      "country: 1 unieke waarden\n",
      "outcode: 167 unieke waarden\n",
      "tenure: 4 unieke waarden\n",
      "propertyType: 19 unieke waarden\n",
      "currentEnergyRating: 7 unieke waarden\n"
     ]
    }
   ],
   "source": [
    "# print de kolommen die niet numeriek zijn\n",
    "non_numeric_cols = data.select_dtypes(include='object').columns\n",
    "non_numeric_cols\n",
    "#print het aantal unieke waarden per kolom\n",
    "for col in non_numeric_cols:\n",
    "    print(f\"{col}: {data[col].nunique()} unieke waarden\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stap voor stap opkuisen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indien geen kolom pstcode aanwezig is, dan deze toevoegen\n",
    "if 'postcode' not in data.columns and 'fullAddress' in data.columns:\n",
    "    # Extracteer postcode uit adres (bijvoorbeeld 'SE5 8AB' uit 'Flat 6, 7 De Crespigny Park, London, SE5 8AB')\n",
    "    data['postcode'] = data['fullAddress'].str.extract(r'(\\w{1,2}\\d{1,2} \\d{1,2}[A-Z]{1,2})', expand=False)\n",
    "    # Verwijder de volledige adreskolom\n",
    "    data.drop(columns='fullAddress', inplace=True)\n",
    "\n",
    "# Omzetten de kolom 'outcode' via labelencoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "for col in ['outcode', 'tenure', 'propertyType', 'currentEnergyRating']:\n",
    "    data[col] = label_encoder.fit_transform(data[col])\n",
    "\n",
    "# slechts één waarde voor country, dus ook weg ermee\n",
    "if 'country' in data.columns: data.drop(columns='country', inplace=True)\n",
    "\n",
    "# de Price kolom is niet normaal verdeeld, dus logaritmisch transformeren\n",
    "data.price = np.log(data.price)\n",
    "\n",
    "# kolommen met objecten verwijderen\n",
    "data = data.select_dtypes(exclude='object')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 266325 entries, 0 to 266324\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   outcode              266325 non-null  int32  \n",
      " 1   latitude             266325 non-null  float64\n",
      " 2   longitude            266325 non-null  float64\n",
      " 3   bathrooms            266325 non-null  float64\n",
      " 4   bedrooms             266325 non-null  float64\n",
      " 5   floorAreaSqM         266325 non-null  float64\n",
      " 6   livingRooms          266325 non-null  float64\n",
      " 7   tenure               266325 non-null  int32  \n",
      " 8   propertyType         266325 non-null  int32  \n",
      " 9   currentEnergyRating  266325 non-null  int32  \n",
      " 10  sale_month           266325 non-null  int64  \n",
      " 11  sale_year            266325 non-null  int64  \n",
      " 12  price                266325 non-null  int64  \n",
      "dtypes: float64(6), int32(4), int64(3)\n",
      "memory usage: 24.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRain-Test-Split, let hier op dat we met een validatie set werken (en geen test set)\n",
    "\n",
    "X =  data.drop(columns=['price'])\n",
    "y =  data['price']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "\n",
    "def evaluate_models(X_train, y_train, X_valid, y_valid):\n",
    "    # Dictionary voor de modellen en hun namen\n",
    "    models = {\n",
    "        'Linear Regression': LinearRegression(),\n",
    "        'Random Forest Regressor': RandomForestRegressor(n_estimators=100, random_state=seed),\n",
    "        'Gradient Boosting Regressor': GradientBoostingRegressor(n_estimators=100, random_state=seed),\n",
    "        'XGBoost Regressor': xgb.XGBRegressor(n_estimators=100, random_state=seed),\n",
    "        # 'Support Vector Regressor': SVR(),\n",
    "        # 'CatBoost Regressor': CatBoostRegressor(\n",
    "        #     use_best_model=True,\n",
    "        #     random_state=seed,\n",
    "        #     verbose=0  # Zet verbose op 0 om minder output te krijgen\n",
    "        # )\n",
    "    }\n",
    "    \n",
    "    # Opslaan van de resultaten\n",
    "    results = {}\n",
    "    \n",
    "    # Itereer over de modellen, train en evalueer\n",
    "    for name, model in models.items():\n",
    "        # Train het model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Voorspel de validatieset\n",
    "        y_pred = model.predict(X_valid)\n",
    "        \n",
    "        # Bereken de evaluatie-metrics\n",
    "        mae = mean_absolute_error(y_valid, y_pred)\n",
    "        mse = mean_squared_error(y_valid, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_valid, y_pred)\n",
    "        \n",
    "        # Voeg de resultaten toe aan de dictionary\n",
    "        results[name] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'R²': r2}\n",
    "    # nog een extra model toevoegen\n",
    "    \n",
    "    cbr = CatBoostRegressor(\n",
    "        use_best_model=True,\n",
    "        random_state=seed,\n",
    "        verbose=200  # Zet verbose op 0 om minder output te krijgen\n",
    "    )\n",
    "    cbr.fit(X_train,\n",
    "            y_train,\n",
    "            eval_set=(X_valid, y_valid),\n",
    "            cat_features=['postcode', 'outcode', 'tenure', 'propertyType', 'currentEnergyRating'],\n",
    "            text_features=['fullAddress'],\n",
    "            early_stopping_rounds=128\n",
    "            )\n",
    "    y_pred_log = cbr.predict(test[X_train.columns.tolist()])\n",
    "    y_pred = np.round(np.expm1(y_pred_log),0).astype(int)\n",
    "\n",
    "    # Bereken de evaluatie-metrics\n",
    "    mae = mean_absolute_error(y_valid, y_pred)\n",
    "    mse = mean_squared_error(y_valid, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_valid, y_pred)\n",
    "    \n",
    "    # Voeg de resultaten toe aan de dictionary\n",
    "    results[name] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'R²': r2}\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Voer de modellen uit en evalueer ze\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Visualiseer de vergelijking\u001b[39;00m\n\u001b[0;32m     36\u001b[0m plot_comparison(results)\n",
      "Cell \u001b[1;32mIn[16], line 28\u001b[0m, in \u001b[0;36mevaluate_models\u001b[1;34m(X_train, y_train, X_valid, y_valid)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Itereer over de modellen, train en evalueer\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Train het model\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# Voorspel de validatieset\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_valid)\n",
      "File \u001b[1;32mc:\\Users\\werne\\anaconda3\\envs\\homl3\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\werne\\anaconda3\\envs\\homl3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\werne\\anaconda3\\envs\\homl3\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\werne\\anaconda3\\envs\\homl3\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\werne\\anaconda3\\envs\\homl3\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\werne\\anaconda3\\envs\\homl3\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\werne\\anaconda3\\envs\\homl3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\werne\\anaconda3\\envs\\homl3\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\werne\\anaconda3\\envs\\homl3\\lib\\site-packages\\sklearn\\tree\\_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \n\u001b[0;32m   1294\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1320\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\werne\\anaconda3\\envs\\homl3\\lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def plot_comparison(results):\n",
    "    # Haal de waarden voor MAE (of een andere metric) uit de results dictionary\n",
    "    models = list(results.keys())\n",
    "    maes = [results[model]['MAE'] for model in models]\n",
    "    mse = [results[model]['MSE'] for model in models]\n",
    "    rmse = [results[model]['RMSE'] for model in models]\n",
    "    r2 = [results[model]['R²'] for model in models]\n",
    "    \n",
    "    # Plot de resultaten\n",
    "    fig, ax = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    # MAE plot\n",
    "    ax[0, 0].barh(models, maes, color='skyblue')\n",
    "    ax[0, 0].set_title('Mean Absolute Error (MAE)')\n",
    "    \n",
    "    # MSE plot\n",
    "    ax[0, 1].barh(models, mse, color='lightgreen')\n",
    "    ax[0, 1].set_title('Mean Squared Error (MSE)')\n",
    "    \n",
    "    # RMSE plot\n",
    "    ax[1, 0].barh(models, rmse, color='salmon')\n",
    "    ax[1, 0].set_title('Root Mean Squared Error (RMSE)')\n",
    "    \n",
    "    # R² plot\n",
    "    ax[1, 1].barh(models, r2, color='lightcoral')\n",
    "    ax[1, 1].set_title('R²')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    save_fig('model_comparison')\n",
    "    plt.show()\n",
    "\n",
    "# Voer de modellen uit en evalueer ze\n",
    "results = evaluate_models(X_train, y_train, X_valid, y_valid)\n",
    "\n",
    "# Visualiseer de vergelijking\n",
    "plot_comparison(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "homl3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
