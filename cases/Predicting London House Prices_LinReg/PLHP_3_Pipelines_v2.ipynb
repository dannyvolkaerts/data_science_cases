{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importeer de benodigde bibliotheken, dan gaat het later sneller \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "import os\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from catboost import CatBoostRegressor\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "# interactieve modus inschakelen en output verbreden\n",
    "%matplotlib inline\n",
    "pd.set_option('display.width', 800)\n",
    "\n",
    "# remove future warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# We egbruiken steeds deze seed voor reproduceerbaarheid\n",
    "seed = 42\n",
    "\n",
    "# path settings\n",
    "p = Path()\n",
    "download_path = p / 'data'\n",
    "output_path = p / 'output'\n",
    "\n",
    "# Kaggle settings\n",
    "api = KaggleApi()\n",
    "api.authenticate()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overzicht files en folders\n",
    "def print_files_folders(path=p):\n",
    "    print(path)\n",
    "    for dirname, _, filenames in os.walk(download_path):\n",
    "        for filename in filenames:\n",
    "            print(os.path.join(dirname, filename))\n",
    "            if 'train.csv' in filename:\n",
    "                print(\"hier:\",os.path.join(dirname, filename))\n",
    "                train_set = os.path.join(dirname, filename)\n",
    "                break\n",
    "\n",
    "def zoek_train_set(path):\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if 'train' in filename: \n",
    "                train_set = os.path.join(dirname, filename)\n",
    "                return train_set\n",
    "def zoek_test_set(path):\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        for filename in filenames:\n",
    "            if 'test' in filename: \n",
    "                train_set = os.path.join(dirname, filename)\n",
    "                return train_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path settings\n",
    "from pathlib import Path\n",
    "p = Path()\n",
    "download_path = p / 'data'\n",
    "output_path = p / 'output'\n",
    "images_path = p / 'images'\n",
    "\n",
    "# Create the output directory if it does not exist\n",
    "if not os.path.exists(output_path):\n",
    "\t\tos.makedirs(output_path)\n",
    "# Create the images directory if it does not exist\n",
    "if not images_path.exists():\n",
    "\timages_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Functie om de output van de gemaakte plots te bewaren\n",
    "def save_fig(fig_name, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = images_path / f\"{fig_name}.{fig_extension}\"\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Lees het bestand in\n",
    "train_set = 'data/train.csv'\n",
    "train_raw = pd.read_csv(train_set, index_col='ID') # hier gebruiken we de ID-kolom als index !!\n",
    "test = pd.read_csv('data/test.csv')\n",
    "sample_submission = pd.read_csv('data/sample_submission.csv')\n",
    "# Vanaf hier werken we verder met 'data' als de trainingset\n",
    "# train_test_split wordt dan X_train en X_valid\n",
    "data = train_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data cleaning en preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling\n",
    "Om een eerste indruk te krijgen over de dataset, maken we gebruik van een profiler.   \n",
    "In het geÃ«xporteerde bestand /output/profiler.html krijg je hierna een mooi overzicht van alle data waaruit deze dataset is opgebouwd.   \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# PROFILER HTML DOCUMENT #\n",
    "##########################\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "import os\n",
    "import webbrowser\n",
    "\n",
    "# controleer of er al een rapport is\n",
    "profiler_file = 'profiler_3_PL.html'\n",
    "profiler_path = os.path.abspath(os.path.join(output_path, profiler_file))\n",
    "if os.path.exists(profiler_path):\n",
    "\tprint(f\"profiler betsaat al. Openen...\")\n",
    "else:\n",
    "\t# Generate the profiling report, kies een goede titel\n",
    "\tprofile = ProfileReport(data, title=\"Baseline London-house-price Report\", explorative=True) # explorative=True om ook de correlaties te zien\n",
    "\n",
    "\n",
    "\n",
    "\t# Save the report as an HTML file\n",
    "\tprofile.to_file(os.path.join(output_path,profiler_file))\n",
    "\n",
    "\t# Pad naar je bestand\n",
    "\tprofiler_path = os.path.abspath(os.path.join(output_path, profiler_file))\n",
    "\tprint(f\"profiler gemaakt: {profiler_path}\")\n",
    "\n",
    "# Open het bestand in de standaardbrowser\n",
    "webbrowser.open(f\"file://{profiler_path}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In de Profiler kan je eigenlijk alles al zien.   \n",
    "Hieronder enkele functies om hier een output te krijgen    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we 'commenten' alles om bij een Run All niet steeds de outputs te moeten maken\n",
    "\"\"\"\"\n",
    "print(f\"Eerste 5 rijen\")\n",
    "print(f\"--------------\")\n",
    "print(data.head())\n",
    "print(f\"Info over de kolommen\")\n",
    "print(f\"-----------------------\")\n",
    "print(data.info())\n",
    "print(f\"statistische info over de numerieke kolommen\")\n",
    "print(\"------------------------\")\n",
    "print(f\"{data.describe(include='all')}\")         #\n",
    "print(f\"aantal rijen en kolommen)\n",
    "print(f\"------------------------\")\n",
    "print(f\"{data.shape}\")              # \n",
    "print(f\"kolomnamen\")\n",
    "print(f\"------------------------\")\n",
    "print(f\"{data.shape}\")              # \n",
    "print(f\"datatype van de kolommen\")\n",
    "print(f\"------------------------\")\n",
    "print(f\"\"{data.columns}\")            # \n",
    "print(f\"datatype van de kolommen\")\n",
    "print(f\"------------------------\")\n",
    "print(f\"{data.dtypes}\")             # \n",
    "print(f\"aantal missende waarden per kolom\")\n",
    "print(f\"------------------------\")\n",
    "print(f\"{data.isnull().sum()}\")     # \n",
    "print(f\"aantal unieke waarden per kolom\")\n",
    "print(f\"------------------------\")\n",
    "print(f\"{data.nunique()}\")          # \n",
    "\n",
    "# Nog een methode is dfsummary\n",
    "from summarytools import dfSummary\n",
    "dfSummary(data) # geeft een mooi overzicht van de data\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vooraleer te starten, eerst wat opschonen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De lege waarden werden opgevuld en de kolommen met te veel missende waarden zijn verwijderd\n"
     ]
    }
   ],
   "source": [
    "# Missende waarden invullen in test- en train-data en kilommen met te veel lege waarden droppen\n",
    "\n",
    "# Functie om NaN-waarden te behandelen\n",
    "# Lijst om kolommen met >50% missende waarden op te slaan\n",
    "cols_to_drop = []\n",
    "\n",
    "def fill_missing_values(df):\n",
    "    for col, missing_count in df.isnull().sum().items():\n",
    "        missing_ratio = missing_count / len(df)\n",
    "        \n",
    "        if 0 < missing_ratio <= 0.5:\n",
    "            if df[col].dtype == object:  # Categorische kolommen\n",
    "                df[col] = df[col].fillna(df[col].mode()[0])\n",
    "            else:  # Numerieke kolommen\n",
    "                df[col] = df[col].fillna(df[col].median())\n",
    "        \n",
    "        elif missing_ratio > 0.5: # meer dan de helft van de waarden ontbreken\n",
    "            cols_to_drop.append(col)\n",
    "\n",
    "# Kolommen met te veel missende waarden verwijderen\n",
    "data = data.drop(columns=cols_to_drop)\n",
    "\n",
    "del cols_to_drop  # Opschoonactie\n",
    "\n",
    "\n",
    "# alleen uitvoeren indien nog lege waarden\n",
    "if data.isnull().sum().sum() > 0:\n",
    "    fill_missing_values(test)\n",
    "    fill_missing_values(data)\n",
    "    print(f\"De lege waarden werden opgevuld en de kolommen met te veel missende waarden zijn verwijderd\")\n",
    "else:\n",
    "    print(\"Er zijn geen missende waarden\")\n",
    "\n",
    "# Onnodige cols schrappen\n",
    "# alleen uitvoeren indien de kolommen nog aanwezig zijn\n",
    "if 'ID' in data.columns:\n",
    "    data = data.drop(columns=['ID', 'country'])\n",
    "    print(f\"De kolommen 'ID' en 'country' zijn verwijderd\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verwijderen van enkele kolommen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full address is verwijderd en de postcode is toegevoegd.\n",
      "Country is verwijderd\n"
     ]
    }
   ],
   "source": [
    "# indien geen kolom postcode aanwezig is, dan deze toevoegen\n",
    "if 'postcode' not in data.columns and 'fullAddress' in data.columns:\n",
    "    # Extracteer postcode uit adres (bijvoorbeeld 'SE5 8AB' uit 'Flat 6, 7 De Crespigny Park, London, SE5 8AB')\n",
    "    data['postcode'] = data['fullAddress'].str.extract(r'(\\w{1,2}\\d{1,2} \\d{1,2}[A-Z]{1,2})', expand=False)\n",
    "# Verwijder de volledige adreskolom\n",
    "if 'fullAddress' in data.columns:\n",
    "    data.drop(columns='fullAddress', inplace=True)\n",
    "    print(f\"Full address is verwijderd en de postcode is toegevoegd.\")\n",
    "else:\n",
    "    print(\"De fullAddress kolom reeds verwijderd.\")\n",
    "\n",
    "# slechts Ã©Ã©n waarde voor country, dus ook weg ermee\n",
    "if 'country' in data.columns: \n",
    "    data.drop(columns='country', inplace=True)\n",
    "    print(f\"Country is verwijderd\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deze is belangrijk.   \n",
    "Gezien de spreiding van de 'Price' kies ik ervoor om een Log-transformatie toe te passen op deze waarden "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-transformatie op 'price' uitgevoerd\n"
     ]
    }
   ],
   "source": [
    "# Target-transformatie (Log-transformatie op `price`) indien niet eerder gebeurd\n",
    "if data['price'].max() > 100:\n",
    "    data['price'] = np.log1p(data[' price'])  # log(1 + price) om log(0) te voorkomen, maar hier geen 0-waarden\n",
    "    print(f\"Log-transformatie op 'price' uitgevoerd\")\n",
    "else:\n",
    "    print(\"Log-transformatie op 'price' werd reeds uitgevoerd\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hier gaat het gebeuren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stap 1: Definieer de preprocessing stappen\n",
    "Label Encoding voor categorische features en StandardScaler voor numerieke features gebruiken.\n",
    "\n",
    "Stap 2: Bouw de pipeline\n",
    "We maken de pipeline voor elke modelvariant en voegen de preprocessing in de pipeline in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-transformatie op 'price' werd reeds uitgevoerd.\n",
      "\n",
      "\n",
      "ð Optimalisatie van LinearRegression met RandomizedSearchCV...\n",
      "â LinearRegression is getraind zonder hyperparameter tuning.\n",
      "\n",
      "ð Optimalisatie van RandomForest met RandomizedSearchCV...\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "â Beste parameters voor RandomForest: {'regressor__n_estimators': 200, 'regressor__min_samples_split': 2, 'regressor__max_depth': 10}\n",
      "\n",
      "ð Optimalisatie van GradientBoosting met RandomizedSearchCV...\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "â Beste parameters voor GradientBoosting: {'regressor__n_estimators': 100, 'regressor__max_depth': 5, 'regressor__learning_rate': 0.1}\n",
      "\n",
      "ð Optimalisatie van CatBoost met RandomizedSearchCV...\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "â Beste parameters voor CatBoost: {'regressor__learning_rate': 0.1, 'regressor__iterations': 500, 'regressor__depth': 6}\n",
      "\n",
      "ð¯ Hyperparameter tuning voltooid voor alle modellen!\n",
      "\n",
      "ð Evaluatie van LinearRegression...\n",
      "â LinearRegression prestaties:\n",
      "   MAE: 0.6131\n",
      "   MSE: 0.6345\n",
      "   RMSE: 0.7966\n",
      "   RÂ²: 0.2578\n",
      "\n",
      "ð Evaluatie van RandomForest...\n",
      "â RandomForest prestaties:\n",
      "   MAE: 0.5910\n",
      "   MSE: 0.5786\n",
      "   RMSE: 0.7607\n",
      "   RÂ²: 0.3232\n",
      "\n",
      "ð Evaluatie van GradientBoosting...\n",
      "â GradientBoosting prestaties:\n",
      "   MAE: 0.5906\n",
      "   MSE: 0.5771\n",
      "   RMSE: 0.7597\n",
      "   RÂ²: 0.3249\n",
      "\n",
      "ð Evaluatie van CatBoost...\n",
      "â CatBoost prestaties:\n",
      "   MAE: 0.5901\n",
      "   MSE: 0.5752\n",
      "   RMSE: 0.7584\n",
      "   RÂ²: 0.3272\n",
      "\n",
      "ð Modelvergelijking:\n",
      "LinearRegression: RÂ²=0.2578, RMSE=0.7966, MAE=0.6131\n",
      "RandomForest: RÂ²=0.3232, RMSE=0.7607, MAE=0.5910\n",
      "GradientBoosting: RÂ²=0.3249, RMSE=0.7597, MAE=0.5906\n",
      "CatBoost: RÂ²=0.3272, RMSE=0.7584, MAE=0.5901\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'outpunt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 130\u001b[0m\n\u001b[0;32m    127\u001b[0m df_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_dict(evaluation_results, orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# Opslaan als CSV\u001b[39;00m\n\u001b[1;32m--> 130\u001b[0m \u001b[43mdf_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutpunt/model_evaluatie_resultaten.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mð Resultaten opgeslagen als \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_evaluatie_resultaten.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_results)\n",
      "File \u001b[1;32mc:\\Users\\werne\\anaconda3\\envs\\homl3\\lib\\site-packages\\pandas\\core\\generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3891\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3893\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3894\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3895\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3899\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3900\u001b[0m )\n\u001b[1;32m-> 3902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3903\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3904\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3905\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3906\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3907\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3908\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3911\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3912\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3913\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3914\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\werne\\anaconda3\\envs\\homl3\\lib\\site-packages\\pandas\\io\\formats\\format.py:1152\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1134\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1135\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1151\u001b[0m )\n\u001b[1;32m-> 1152\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1155\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\werne\\anaconda3\\envs\\homl3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:247\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    257\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    258\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    264\u001b[0m     )\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\werne\\anaconda3\\envs\\homl3\\lib\\site-packages\\pandas\\io\\common.py:739\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 739\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    743\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\werne\\anaconda3\\envs\\homl3\\lib\\site-packages\\pandas\\io\\common.py:604\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    602\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'outpunt'"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OrdinalEncoder, FunctionTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from scipy.stats import randint\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "\n",
    "# 1. Target-transformatie (Log-transformatie op `price`)\n",
    "if data['price'].max() > 100:\n",
    "    data['price'] = np.log1p(data[' price'])  # log(1 + price) om log(0) te voorkomen, maar hier geen 0-waarden\n",
    "    print(f\"Log-transformatie op 'price' uitgevoerd.\\n\")\n",
    "else:\n",
    "    print(\"Log-transformatie op 'price' werd reeds uitgevoerd.\\n\")\n",
    "\n",
    "# 2. Splitsen in features (X) en target (y)\n",
    "X = data.drop(columns=['price'])\n",
    "y = data['price']\n",
    "\n",
    "# 3. Train-test split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=seed)\n",
    "\n",
    "# 4. Pipeline setup\n",
    "num_features = ['bathrooms', 'bedrooms', 'floorAreaSqM', 'livingRooms']\n",
    "cat_features = ['tenure', 'propertyType', 'currentEnergyRating']\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', StandardScaler(), num_features),\n",
    "    ('cat', OrdinalEncoder(), cat_features),\n",
    "])\n",
    "\n",
    "# Definieer de pipelines voor verschillende modellen\n",
    "pipelines = {\n",
    "    'LinearRegression': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', LinearRegression())\n",
    "    ]),\n",
    "    'RandomForest': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', RandomForestRegressor(random_state=seed))\n",
    "    ]),\n",
    "    'GradientBoosting': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', GradientBoostingRegressor(random_state=seed))\n",
    "    ]),\n",
    "    'CatBoost': Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', CatBoostRegressor(verbose=0, random_state=seed))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Hyperparameter grids voor elk model\n",
    "param_grids = {\n",
    "    'LinearRegression': {},  # Geen hyperparameter tuning nodig\n",
    "    'RandomForest': {\n",
    "        'regressor__n_estimators': [50, 100, 200],\n",
    "        'regressor__max_depth': [5, 10, 20],\n",
    "        'regressor__min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'regressor__n_estimators': [50, 100, 200],\n",
    "        'regressor__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'regressor__max_depth': [3, 5, 10]\n",
    "    },\n",
    "    'CatBoost': {\n",
    "        'regressor__iterations': [100, 200, 500],  \n",
    "        'regressor__learning_rate': [0.01, 0.05, 0.1],  \n",
    "        'regressor__depth': [4, 6, 10]\n",
    "}\n",
    "}\n",
    "\n",
    "# Train modellen met hyperparameter tuning\n",
    "best_models = {}\n",
    "\n",
    "for name, model in pipelines.items():\n",
    "    print(f\"\\nð Optimalisatie van {name} met RandomizedSearchCV...\")\n",
    "\n",
    "    if param_grids[name]:  # Alleen tunen als er parameters zijn\n",
    "        search = RandomizedSearchCV(model, param_distributions=param_grids[name],\n",
    "                                    n_iter=10, cv=3, scoring='r2',\n",
    "                                    n_jobs=-1, verbose=2, random_state=seed)\n",
    "        \n",
    "        search.fit(X_train, y_train)\n",
    "        best_models[name] = search.best_estimator_\n",
    "        print(f\"â Beste parameters voor {name}: {search.best_params_}\")\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        best_models[name] = model\n",
    "        print(f\"â {name} is getraind zonder hyperparameter tuning.\")\n",
    "\n",
    "print(\"\\nð¯ Hyperparameter tuning voltooid voor alle modellen!\")\n",
    "\n",
    "# --- ð¹ Evaluatie van alle modellen ð¹ ---\n",
    "evaluation_results = {}\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    print(f\"\\nð Evaluatie van {name}...\")\n",
    "\n",
    "    y_pred = model.predict(X_valid)\n",
    "\n",
    "    mae = mean_absolute_error(y_valid, y_pred)\n",
    "    mse = mean_squared_error(y_valid, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_valid, y_pred)\n",
    "\n",
    "    evaluation_results[name] = {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'RÂ²': r2}\n",
    "\n",
    "    print(f\"â {name} prestaties:\")\n",
    "    print(f\"   MAE: {mae:.4f}\")\n",
    "    print(f\"   MSE: {mse:.4f}\")\n",
    "    print(f\"   RMSE: {rmse:.4f}\")\n",
    "    print(f\"   RÂ²: {r2:.4f}\")\n",
    "\n",
    "# --- ð Overzicht van alle resultaten ---\n",
    "print(\"\\nð Modelvergelijking:\")\n",
    "for model, scores in evaluation_results.items():\n",
    "    print(f\"{model}: RÂ²={scores['RÂ²']:.4f}, RMSE={scores['RMSE']:.4f}, MAE={scores['MAE']:.4f}\")\n",
    "\n",
    "# Zet de evaluatieresultaten om naar een pandas DataFrame\n",
    "df_results = pd.DataFrame.from_dict(evaluation_results, orient='index')\n",
    "\n",
    "# Opslaan als CSV\n",
    "df_results.to_csv(\"output/model_evaluatie_resultaten.csv\", index=True)\n",
    "\n",
    "print(\"\\nð Resultaten opgeslagen als 'model_evaluatie_resultaten.csv'\")\n",
    "print(df_results)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sorteer modellen op RÂ²-score\n",
    "df_results_sorted = df_results.sort_values(by='RÂ²', ascending=False)\n",
    "\n",
    "# Staafdiagram maken\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=df_results_sorted.index, y=df_results_sorted['RÂ²'], palette='viridis')\n",
    "\n",
    "# Labels en titel\n",
    "plt.ylabel(\"RÂ² Score\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.title(\"ð Modelvergelijking: RÂ²-scores\")\n",
    "plt.ylim(0, 1)  # RÂ² varieert tussen 0 en 1\n",
    "plt.xticks(rotation=30)  # Kantel labels voor leesbaarheid\n",
    "\n",
    "# Toon de grafiek\n",
    "save_fig(\"model_vergelijking RÂ²-scores\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log = best_pipeline.predict(test)\n",
    "y_pred = np.round(np.expm1(y_pred_log),0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nodig om het resultaat in te dienen\n",
    "sub = sample_submission.copy()\n",
    "sub['price'] = y_pred\n",
    "sub.to_csv('output/submission_cbr_log.csv', index=False)\n",
    "sub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "homl3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
